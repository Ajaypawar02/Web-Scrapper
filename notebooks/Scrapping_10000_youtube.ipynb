{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "\n",
        "# Set up the YouTube Data API client\n",
        "\n",
        "def scapping_youtube():\n",
        "  api_service_name = \"youtube\"\n",
        "  api_version = \"v3\"\n",
        "  api_key = \"AIzaSyBZI7KXEAtsLC5hNT-bq6g4Clj3lqEIofc\"  # Replace with your own API key\n",
        "  youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=api_key)\n",
        "  links = []\n",
        "  # Perform a searc\n",
        "  max_results = 10000\n",
        "  results_per_page = 50\n",
        "  next_page_list = []\n",
        "  count = 0\n",
        "\n",
        "  pages = max_results // results_per_page\n",
        "\n",
        "  for page in range(pages):\n",
        "    search_query = \"https://openinapp.com\"\n",
        "    request = youtube.search().list(\n",
        "        part=\"snippet\",\n",
        "        q=search_query,\n",
        "        type=\"video\",\n",
        "        maxResults=50, # You can adjust the maximum number of results as needed\n",
        "        pageToken = None if page==0 else next_page,\n",
        "    )\n",
        "    response = request.execute()\n",
        "    next_page = response.get(\"nextPageToken\")\n",
        "    print(next_page)\n",
        "    next_page_list.append(next_page)\n",
        "\n",
        "    # Extract the video IDs and construct the YouTube links\n",
        "    youtube_links = []\n",
        "    for item in response[\"items\"]:\n",
        "        video_id = item[\"id\"][\"videoId\"]\n",
        "        youtube_link = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "        youtube_links.append(youtube_link)\n",
        "\n",
        "    # Print the YouTube links\n",
        "    for link in youtube_links:\n",
        "        count += 1\n",
        "        print(link)\n",
        "        links.append(link)\n",
        "\n",
        "  return links\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BCIEli6Hv8T2"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    scrapper = scapping_youtube()\n",
        "    df = pd.DataFrame(scrapper, columns = [\"Links\"])\n",
        "    df.iloc[:10000]\n",
        "    df.to_csv(\"youtube_liinks_10000.csv\", index = False)\n",
        "    print(df)"
      ],
      "metadata": {
        "id": "DH2llZ81_JCF"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wshO3mc_CvEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}